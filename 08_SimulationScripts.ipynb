{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation Scripts {#sec-simulationscripts}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we introduce scripts which support the simulation of CRLD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " #| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " #| default_exp SimulationScripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " #| export\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skopt.sampler import Lhs\n",
    "from skopt.space import Space\n",
    "import hashlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create initial strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " #| exports\n",
    "def initial_strategies(MAEi,  # Multi-agent environment interface\n",
    "                       number:int,  # Number of strategies to create\n",
    "                       iterations:int=1000  # Latin hyper cube sampling parameter\n",
    "                       )->np.ndarray:  # Array of initial strategies\n",
    "    \"\"\"\n",
    "    Create a set of inital strategies using latin hyper cube sampling\n",
    "    \"\"\"\n",
    "    assert MAEi.M == 2, 'Sampling for M>2 not straightforward'\n",
    "    # https://www.egr.msu.edu/~kdeb/papers/c2018010.pdf\n",
    "    # https://www.cs.cmu.edu/~nasmith/papers/smith+tromble.tr04.pdf\n",
    "    \n",
    "    eps = 10**(-6)\n",
    "    space = Space(MAEi.N * MAEi.Q * (MAEi.M-1)*[(0.0+eps, 1.0-eps)])\n",
    "    \n",
    "    # generate latin hyper cubes\n",
    "    lhs = Lhs(criterion=\"maximin\", iterations=iterations)\n",
    "    x = lhs.generate(space.dimensions, number, random_state=42)\n",
    "    x = np.array(x).reshape(number, MAEi.N, MAEi.Q, MAEi.M-1)\n",
    "    \n",
    "    # complete and normalize\n",
    "    inits = np.zeros((number, MAEi.N, MAEi.Q, MAEi.M))\n",
    "    inits[..., 0] = x[...,0]\n",
    "    inits[..., 1] = 1 - x[...,0]\n",
    "    \n",
    "    return inits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 3, 4, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class mae: N=3; Q=4; M=2 # dummy MAEi for demonstration only\n",
    "Xs = initial_strategies(mae, 7)\n",
    "Xs.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " #| exports\n",
    "def compute_trajectories(MAEi,  # Multi-agent environment interface\n",
    "                         inits,  # Iterable of inital conditions\n",
    "                         Tmax=1000,  # Number of maximum iteration steps for each run\n",
    "                         tol=10e-5  # Tolerance to classify a trajectory as converged\n",
    "                         )->tuple:  # (iterables of trajectories, fixed-point-reacheds)\n",
    "    \"\"\"\n",
    "    Compute learning trajectories from a set of inital strategies.\n",
    "    \"\"\"\n",
    "    trjs = []; fprs = []\n",
    "    leni = len(inits)\n",
    "    \n",
    "    for xi, x0 in enumerate(inits):\n",
    "        print(\"\\r \", np.round(xi/leni, 4), end='')\n",
    "        x = x0.copy()\n",
    "        \n",
    "        trj, fpr = MAEi.trajectory(x, Tmax=Tmax, tolerance=tol)\n",
    "        \n",
    "        trjs.append(trj)\n",
    "        fprs.append(fpr)\n",
    "        \n",
    "    print()\n",
    "    print('Computed', leni, 'trajectories')\n",
    "    \n",
    "    return np.array(trjs, dtype=object), np.array(fprs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After computing the trajectories, we can check whether or not all converged and look at the histograms of their lengths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " #| exports\n",
    "def check_run(trjs,  # Iterable of learning trajectories\n",
    "              fprs=None):  # Iterable of bools whether a fixed point was reached\n",
    "    \"\"\"\n",
    "    Perform some checks for an iterable of learning trajectories\n",
    "    \"\"\"\n",
    "    if fprs is not None:\n",
    "        print('Unique fixed points reached:', np.unique(fprs))\n",
    "    plt.hist([len(traj) for traj in trjs], bins=20);\n",
    "    plt.title('Histrogram of trajectories lengths')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving & reloading\n",
    "To not recompute everything from scratch, we save runs to disk and retrieve them more efficiently and faster when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " #| exports\n",
    "def _transform_tensor_into_hash(tens):\n",
    "    \"\"\"Transform `tens` into a string for filename saving\"\"\"\n",
    "    r = int(hashlib.sha512(str(tens).encode('utf-8')).hexdigest()[:16], 16)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " #| exports\n",
    "def obtain_trajectories(MAEi,  # Multi-agent environment interface\n",
    "                        inits,  # Iterable of inital conditions\n",
    "                        Tmax=1000,  # Number of maximum iteration steps for each run\n",
    "                        tol=10e-5,  # Tolerance to classify a trajectory as converged\n",
    "                        ddir='data',  # Path to data directory to store the results\n",
    "                        verbose=1  # Verbosity level\n",
    "                        )->tuple:  # (iterables of trajectories, fixed-point-reacheds)\n",
    "    \"\"\"\n",
    "    Obtain learning trajectories from a set of inital strategies.\n",
    "    Check wether you can load them from disk. If yes, do so. If not, compute.\n",
    "    \"\"\"\n",
    "    fn = ddir + '/' + MAEi.id() + '_' + str(_transform_tensor_into_hash(inits))\n",
    "    fn += \".npz\"\n",
    "    \n",
    "    try:\n",
    "        dat = np.load(fn, allow_pickle=True)\n",
    "        ddic = dict(zip((k for k in dat), (dat[k] for k in dat)))\n",
    "        print(\"Loading \", fn) if verbose else None\n",
    "    \n",
    "    except:\n",
    "        print(\"Computing \", fn) if verbose else None\n",
    "        trjs, fprs = compute_trajectories(MAEi, inits, Tmax=Tmax, tol=tol)\n",
    "        check_run(trjs, fprs)\n",
    "        # rtrajs = obtain_rewards(AEi, Ï€trajs)\n",
    "        \n",
    "        ddic = dict(trjs=trjs, fprs=fprs)\n",
    "        np.savez_compressed(fn, **ddic)\n",
    "        dat = np.load(fn, allow_pickle=True)\n",
    "        ddic = dict(zip((k for k in dat), (dat[k] for k in dat)))\n",
    "    \n",
    "    return ddic['trjs'], ddic['fprs']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " #| exports\n",
    "def final_rewards(MAEi, # Multi-agent environment interface\n",
    "                  trjs  # Iterable of learning trajectories\n",
    "                  )->np.ndarray:  # Array of final rewards\n",
    "    \"\"\"\n",
    "    Compute final rewards from a set of learning trajectories.\n",
    "    \"\"\"\n",
    "    rews = []\n",
    "    for trj in trjs:\n",
    "        x = trj[-1].astype(float)\n",
    "        rs = np.einsum(MAEi.Ps(x), [0], MAEi.Ris(x), [1,0], [1])        \n",
    "        # rs = MAEi.Ri(x)\n",
    "        rews.append(rs)\n",
    "        \n",
    "    return np.array(rews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " #| hide\n",
    "import nbdev\n",
    "nbdev.export.nb_export(\"08_SimulationScripts.ipynb\", \"_code\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
